{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName('Practica_pyspark').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear un DataFrame con datos de personas, que incluya nombre, edad y ciudad de residencia.\n",
    "data = [(\"Alice\", 25, \"New York\"),\n",
    "        (\"Bob\", 30, \"Los Angeles\"),\n",
    "        (\"Charlie\", 22, \"Chicago\")]\n",
    "\n",
    "columns = ['nombre', 'edad', 'ciudad']\n",
    "\n",
    "df = spark.createDataFrame(data, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| nombre|\n",
      "+-------+\n",
      "|  Alice|\n",
      "|    Bob|\n",
      "|Charlie|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Mostrar solo los nombres de las personas del DataFrame.\n",
    "df.select(\"nombre\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----------+\n",
      "|nombre|edad|     ciudad|\n",
      "+------+----+-----------+\n",
      "| Alice|  25|   New York|\n",
      "|   Bob|  30|Los Angeles|\n",
      "+------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Filtrar personas cuya edad sea mayor o igual a 25.\n",
    "df.filter(df[\"edad\"] >= 25).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Agregar una nueva columna \"Pais\" con un valor constante para todas las filas.\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df = df.withColumn(\"pais\", lit(\"Estados Unidos\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         avg(edad)|\n",
      "+------------------+\n",
      "|25.666666666666668|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. Calcular el promedio de edad de todas las personas.\n",
    "from pyspark.sql.functions import avg\n",
    "\n",
    "df.select(avg(\"edad\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+--------------+\n",
      "| nombre|edad|     ciudad|          pais|\n",
      "+-------+----+-----------+--------------+\n",
      "|    Bob|  30|Los Angeles|Estados Unidos|\n",
      "|  Alice|  25|   New York|Estados Unidos|\n",
      "|Charlie|  22|    Chicago|Estados Unidos|\n",
      "+-------+----+-----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Ordenar el DataFrame por edad en orden descendente.\n",
    "df.orderBy(df[\"edad\"].desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|     ciudad|count|\n",
      "+-----------+-----+\n",
      "|   New York|    1|\n",
      "|Los Angeles|    1|\n",
      "|    Chicago|    1|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7. Agrupar por ciudad y calcular la cantidad de personas en cada ciudad.\n",
    "df.groupBy(\"ciudad\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Renombrar la columna \"Nombre\" a \"NombreCompleto\".\n",
    "df = df.withColumnRenamed(\"nombre\", \"nombreCompleto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Eliminar la columna \"Edad\" del DataFrame.\n",
    "df_drop = df.drop(\"edad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+\n",
      "| nombre|edad|     ciudad|\n",
      "+-------+----+-----------+\n",
      "|  Alice|  25|   New York|\n",
      "|    Bob|  30|Los Angeles|\n",
      "|Charlie|  22|    Chicago|\n",
      "+-------+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 10. Realizar una consulta SQL en el DataFrame para seleccionar personas mayores de 20 años.\n",
    "df.createOrReplaceTempView(\"personas\")\n",
    "resultado_sql = spark.sql(\"SELECT * FROM personas WHERE edad >= 20\")\n",
    "resultado_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|sum(edad)|\n",
      "+---------+\n",
      "|       77|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11. Calcular la suma total de todas las edades.\n",
    "from pyspark.sql.functions import sum\n",
    "\n",
    "df.select(sum(\"edad\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|min(Edad)|max(edad)|\n",
      "+---------+---------+\n",
      "|       22|       30|\n",
      "+---------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 12. Calcular la edad mínima y máxima de todas las personas.\n",
    "from pyspark.sql.functions import min, max\n",
    "\n",
    "df.select(min(\"Edad\"), max(\"edad\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-------+---------+\n",
      "| nombre|edad| ciudad|RangoEdad|\n",
      "+-------+----+-------+---------+\n",
      "|Charlie|  22|Chicago|    21-40|\n",
      "+-------+----+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 13. Filtrar personas cuya ciudad de residencia sea \"Chicago\" y edad sea menor de 30.\n",
    "df.filter((df[\"ciudad\"] == \"Chicago\") & (df[\"edad\"] < 30)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Agregar una nueva columna \"EdadDuplicada\" que contenga el doble de la edad.\n",
    "df = df.withColumn(\"edadDuplicada\", df[\"edad\"] * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Convertir todas las edades en años a meses.\n",
    "df = df.withColumn(\"edadEnMeses\", df[\"edad\"] * 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de personas: 3\n"
     ]
    }
   ],
   "source": [
    "# 16. Contar el número total de personas en el DataFrame.\n",
    "total_personas = df.count()\n",
    "print(\"Total de personas:\", total_personas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----------+--------------+-------------+-----------+\n",
      "| nombre|edad|     ciudad|          pais|edadDuplicada|edadEnMeses|\n",
      "+-------+----+-----------+--------------+-------------+-----------+\n",
      "|    Bob|  30|Los Angeles|Estados Unidos|           60|        360|\n",
      "|Charlie|  22|    Chicago|Estados Unidos|           44|        264|\n",
      "+-------+----+-----------+--------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 17. Filtrar personas cuya edad sea un número par.\n",
    "df.filter(df[\"edad\"] % 2 == 0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|RangoEdad|count|\n",
      "+---------+-----+\n",
      "|    21-40|    3|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 18. Calcular la cantidad de personas por rango de edades (0-20, 21-40, 41-60, 61+).\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn(\"RangoEdad\", when((df[\"edad\"] >= 0) & (df[\"edad\"] <= 20), \"0-20\")\n",
    "                    .when((df[\"edad\"] >= 21) & (df[\"edad\"] <= 40), \"21-40\")\n",
    "                    .when((df[\"edad\"] >= 41) & (df[\"edad\"] <= 60), \"41-60\")\n",
    "                    .otherwise(\"61+\"))\n",
    "\n",
    "df.groupBy(\"RangoEdad\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|nombreCompleto|count|\n",
      "+--------------+-----+\n",
      "|         Alice|    1|\n",
      "|           Bob|    1|\n",
      "|       Charlie|    1|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 19. Contar cuántas personas tienen el mismo nombre.\n",
    "df.groupBy(\"nombreCompleto\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+-----------+---------+-------------------+\n",
      "|nombreCompleto|edad|     ciudad|RangoEdad|InformacionPersonal|\n",
      "+--------------+----+-----------+---------+-------------------+\n",
      "|         Alice|  25|   New York|    21-40|    Alice, New York|\n",
      "|           Bob|  30|Los Angeles|    21-40|   Bob, Los Angeles|\n",
      "|       Charlie|  22|    Chicago|    21-40|   Charlie, Chicago|\n",
      "+--------------+----+-----------+---------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 20. Concatenar las columnas \"Nombre\" y \"Ciudad\" en una nueva columna llamada \"InformacionPersonal\".\n",
    "from pyspark.sql.functions import concat_ws\n",
    "\n",
    "df = df.withColumn(\"InformacionPersonal\", concat_ws(\", \", df[\"nombreCompleto\"], df[\"ciudad\"]))\n",
    "\n",
    "df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
